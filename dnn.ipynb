{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deep neural networks \n",
    "\n",
    "공식문서 참고 \n",
    "-caffe \n",
    "https://github.com/opencv/opencv/tree/master/samples/dnn/face_detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 1024 pixels\n",
      "height: 799 pixels\n",
      "channels: 3\n",
      "0.7888598 822 218 887 295\n",
      "0.5265784 27 230 84 300\n",
      "0.42828155 776 294 833 373\n",
      "0.4034103 691 209 742 276\n",
      "0.4020443 669 305 717 373\n",
      "0.38266662 412 260 462 335\n",
      "0.3719502 307 188 360 252\n",
      "0.36000493 455 213 512 281\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model_name = './opencv_dnn_202005/opencv_dnn_202005/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "prototxt_name = './opencv_dnn_202005/opencv_dnn_202005/deploy.prototxt.txt'\n",
    "min_confidence = 0.3\n",
    "file_name = \"./opencv_dnn_202005/opencv_dnn_202005/image/marathon_01.jpg\"\n",
    "\n",
    "def detectAndDisplay(frame):\n",
    "    model = cv2.dnn.readNetFromCaffe(prototxt_name, model_name)\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame,(300,300)),1.0,(300,300),(104.0,177.0,123.0))\n",
    "    \n",
    "    model.setInput(blob)\n",
    "    detections = model.forward()\n",
    "    \n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "            # extract the confidence (i.e., probability) associated with the\n",
    "            # prediction\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "            # filter out weak detections by ensuring the `confidence` is\n",
    "            # greater than the minimum confidence\n",
    "            if confidence > min_confidence:\n",
    "                    # compute the (x, y)-coordinates of the bounding box for the\n",
    "                    # object\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                    print(confidence, startX, startY, endX, endY)\n",
    "     \n",
    "                    # draw the bounding box of the face along with the associated\n",
    "                    # probability\n",
    "                    text = \"{:.2f}%\".format(confidence * 100)\n",
    "                    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "                            (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, text, (startX, y),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # show the output image\n",
    "    cv2.imshow(\"Face Detection by dnn\", frame)\n",
    "\n",
    "img = cv2.imread(file_name)\n",
    "print(\"width: {} pixels\".format(img.shape[1]))\n",
    "print(\"height: {} pixels\".format(img.shape[0]))\n",
    "print(\"channels: {}\".format(img.shape[2]))\n",
    "\n",
    "(height, width) = img.shape[:2]\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "\n",
    "detectAndDisplay(img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
